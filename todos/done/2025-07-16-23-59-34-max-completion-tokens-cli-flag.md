# Max completion tokens CLI flag
**Status:** Done
**Agent PID:** 46914

## Original Todo
apps/claude-bridge we need a way to set max_completion_tokens as a cli flag and override the completion tokens Claude Code specifies in its request.

  ```bash
  âžœ  claude-bridge git:(main) âœ— npx tsx src/cli.ts openai moonshotai/kimi-k2-instruct --baseURL https://api.groq.com/openai/v1 --apiKey $GROQ_API_KEY
  âš ï¸  Unknown model for openai: moonshotai/kimi-k2-instruct
  This model is not in our registry but will be attempted.
  Known openai models:
      gpt-4-turbo
      gpt-4-turbo-2024-04-09
      gpt-4-turbo-preview
      ... and 24 more
  Run 'claude-bridge openai' to see all known models

  âš ï¸  Model capabilities unknown for: moonshotai/kimi-k2-instruct
  Tool and image support cannot be validated.

  ðŸŒ‰ Claude Bridge starting:
  Provider: openai
  Model: moonshotai/kimi-k2-instruct
  ðŸš€ Launching: node --import /Users/badlogic/workspaces/lemmy/apps/claude-bridge/src/interceptor-loader.js /Users/badlogic/.claude/local/node_modules/@anthropic-ai/claude-code/cli.js
  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
  â”‚ âœ» Welcome to Claude Code!                                   â”‚
  â”‚                                                             â”‚
  â”‚   /help for help, /status for your current setup            â”‚
  â”‚                                                             â”‚
  â”‚   cwd: /Users/badlogic/workspaces/lemmy/apps/claude-bridge  â”‚
  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

  â€» Tip: Send messages to Claude while it works to steer Claude in real-time

  > how you going?
  âŽ¿  API Error (Connection error.) Â· Retrying in 1 secondsâ€¦ (attempt 1/10)
      âŽ¿  Error (400 `max_completion_tokens` must be less than or equal to `16384`, the maximum value for `max_completion_tokens` is less than the `context_window` for this model)
  âŽ¿  API Error (Connection error.) Â· Retrying in 1 secondsâ€¦ (attempt 2/10)
      âŽ¿  Error (400 `max_completion_tokens` must be less than or equal to `16384`, the maximum value for `max_completion_tokens` is less than the `context_window` for this model)
  âŽ¿  API Error (Connection error.) Â· Retrying in 2 secondsâ€¦ (attempt 3/10)
      âŽ¿  Error (400 `max_completion_tokens` must be less than or equal to `16384`, the maximum value for `max_completion_tokens` is less than the `context_window` for this model)
  ```

## Description
Add a `--max-output-tokens` CLI flag to claude-bridge that allows users to override the max output tokens for any provider. This maps to `maxOutputTokens` in the BaseAskOptions, which OpenAI's client then converts to `max_completion_tokens`. This is needed because some models (especially those not in the registry) have stricter token limits than what Claude Code requests by default, causing API errors.

## Implementation Plan
- [x] Add `--max-output-tokens` CLI flag parsing in apps/claude-bridge/src/cli.ts
- [x] Add `maxOutputTokens?: number` to BridgeConfig interface in apps/claude-bridge/src/types.ts
- [x] Serialize entire BridgeConfig to JSON and pass via single CLAUDE_BRIDGE_CONFIG env var in apps/claude-bridge/src/cli.ts
- [x] Update interceptor to parse BridgeConfig from CLAUDE_BRIDGE_CONFIG env var in apps/claude-bridge/src/interceptor.ts
- [x] Apply maxOutputTokens override in callProvider method in apps/claude-bridge/src/interceptor.ts:237
- [x] Add validation that max-output-tokens is a positive integer
- [x] Test with the problematic model from the todo example

## Notes
- Using a single CLAUDE_BRIDGE_CONFIG env var with JSON serialization for cleaner config passing
- The maxOutputTokens applies to all providers (not just OpenAI) as it's in BaseAskOptions
- OpenAI client automatically converts maxOutputTokens to max_completion_tokens